{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to pull html from test pages\n",
    "def scrape(url_roots: list[str]):\n",
    "    combined_pages_html = []\n",
    "    max_length = 0\n",
    "    for root in url_roots:\n",
    "        url = root + 'i.html'\n",
    "        message = f'requesting {url} ({url_roots.index(root) + 1}/{len(url_roots)})'\n",
    "        max_length = max(max_length, len(message))\n",
    "        print(f'\\r{message.ljust(max_length)}', end=' ', flush=True)\n",
    "        sleep(30) # 30-second delay between requests\n",
    "        page_html = requests.get(url)\n",
    "        combined_pages_html.append(page_html)\n",
    "    # After the loop, print a final message that clears the last line\n",
    "    print(f'\\rscraping complete: {url_roots.index(root) + 1}/{len(url_roots)}'.ljust(max_length))\n",
    "    return combined_pages_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create helper functions for parsing data fields\n",
    "# Function for parsing names of coin subjects\n",
    "def pull_title(soup):\n",
    "    raw_title = soup.find('title').text\n",
    "    sep_index = raw_title.find(',')\n",
    "    if sep_index == -1:\n",
    "        sep_index = raw_title.find('-')\n",
    "    return raw_title[:sep_index].strip() if sep_index != -1 else raw_title.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to pull subtitles\n",
    "def pull_subtitle(soup):\n",
    "    possible_locations = [\n",
    "        lambda s: s.find_all('h3')[0].contents[-1],\n",
    "        lambda s: s.find('font').contents[0],\n",
    "        lambda s: s.find_all('p')[1].contents[-1],\n",
    "        lambda s: s.find_all('br')[0].contents[0],\n",
    "    ]\n",
    "    \n",
    "    for get_subtitle in possible_locations:\n",
    "        try:\n",
    "            subtitle = get_subtitle(soup)\n",
    "            if not subtitle or len(str(subtitle)) < 4:\n",
    "                continue\n",
    "            if any(keyword in str(subtitle) for keyword in ['Click', 'Browse']):\n",
    "                continue\n",
    "            if '(' in str(subtitle) or '<' in str(subtitle):\n",
    "                return None\n",
    "            return str(subtitle).strip()\n",
    "        except (IndexError, AttributeError):\n",
    "            continue \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to pull raw coin data\n",
    "def pull_coins(soup):\n",
    "    coins = [coin.contents for coin in soup.find_all('tr') if len(coin) >2 and 'bgcolor' in str(coin)]\n",
    "    return coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to pull coin descriptions\n",
    "def coin_description(coin):\n",
    "    try:\n",
    "        description_html = str(coin[1])\n",
    "        match = re.search(r'<td[^>]*>([^<]+)</td>', description_html)\n",
    "        if match:\n",
    "            description = match.group(1)  # The captured group from the regex\n",
    "            return description.strip()\n",
    "    except IndexError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to identify coin metal\n",
    "def coin_metal(coin):\n",
    "    metals = {'#B8':'Copper','#b8':'Copper', '#FF':'Gold', '#C0':'Silver', '#B7':'Brass', '#b7':'Brass', 'red':'FAKE'}\n",
    "    coin = str(coin)\n",
    "    try:\n",
    "        bg_color_index = int(coin.find('bgcolor=')) + 9\n",
    "        bg_color = coin[bg_color_index:bg_color_index + 3]\n",
    "        metal = metals[bg_color]\n",
    "    except:\n",
    "        return None\n",
    "    return metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to pull coin era (i.e. 'AD' or 'BC') \n",
    "def coin_era(coin):\n",
    "    match = re.search(r'\\b(AD|BC)\\b', str(coin))\n",
    "    return match.group(0) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to pull a year (not *every* year) in the coin description\n",
    "# (if there is a range of years i.e. 117-124 AD, function pulls the year closest to era i.e. '117-124 AD' returns '124', while 'AD 117-124' returns '117')\n",
    "def coin_year(coin):\n",
    "    era = coin_era(coin)\n",
    "    if not era:\n",
    "        return None\n",
    "\n",
    "    if era == 'AD':\n",
    "        # Look for the year pattern before 'AD'\n",
    "        match = re.search(r'(\\d{1,4})(?=\\s*AD)', str(coin))\n",
    "    else:\n",
    "        # Look for the year pattern before 'BC'\n",
    "        match = re.search(r'(\\d{1,4})(?=\\s*BC)', str(coin))\n",
    "\n",
    "    if not match:\n",
    "        # If no year is found before the era, search after it\n",
    "        match = re.search(r'(?<=\\bAD\\s)(\\d{1,4})', str(coin)) if era == 'AD' else re.search(r'(?<=\\bBC\\s)(\\d{1,4})', str(coin))\n",
    "\n",
    "    if match:\n",
    "        year = int(match.group(0))\n",
    "        return year if era == 'AD' else -year\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to pull .txt urls\n",
    "def coin_txt(coin):\n",
    "    for item in coin:\n",
    "        match = re.search(r'href=\"([^\"]+\\.txt)\"', str(item))\n",
    "        if match:\n",
    "            return match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to pull coin ids from jpg or txt urls\n",
    "def coin_id(coin):\n",
    "    coin = str(coin)\n",
    "    match = re.search(r'href=\"_*([^\"]+?)\\.(jpg|txt)\"', coin)\n",
    "    if match:\n",
    "        return match.group(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to pull coin mass (in grams)\n",
    "def coin_mass(coin):\n",
    "    coin = str(coin)\n",
    "    gram_variations = [r'\\bgr\\b', r'\\bgm\\b', r'\\bg\\b'] \n",
    "    \n",
    "    def extract_mass(pattern, coin_text):\n",
    "        match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*' + pattern, coin_text)\n",
    "        if match:\n",
    "            num_str = match.group(1).replace(',', '.')\n",
    "            try:\n",
    "                return float(num_str)\n",
    "            except ValueError:\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "    for grams in gram_variations:\n",
    "        mass = extract_mass(grams, coin)\n",
    "        if mass is not None:\n",
    "            return mass\n",
    "            \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to pull coin diameter (in mm)\n",
    "def coin_diameter(coin):\n",
    "    coin = str(coin)\n",
    "    pattern = re.compile(r'(\\d+(\\.\\d*)?)\\s*mm')\n",
    "\n",
    "    match = pattern.search(coin)\n",
    "    \n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for common inscriptions\n",
    "''' ...such as \"AVG\" (Augustus, title of the emperor), \"IMP\" (Imperator \n",
    "(victorious general), received upon accession), \"CAES\" (Caesar, inherited name \n",
    "of the Julian family (Julius Caesar), used by later emperors to designate heir), \n",
    "\"GERM\" (Germanicus, a title honoring military victories in Germany), \"COS\" or \n",
    "\"CONSVL\" (Consul, a title linked to highest office in Senate, usually held by \n",
    "emperor), \"PO\" (Pontifex Maximus, highest priest, the head of state religion), \n",
    "\"PP\" (Pater Patriae, father of the country), \"PF\" (Pius Felix, reverent or \n",
    "dutiful), \"SC\" (Senatus Consultus), \"TPP\" (Tribunica Potestate, tribune of the \n",
    "people, each renewal indicated by numerals), \"CENS\" (Censor, a public office \n",
    "overseeing taxes, morality, the census and membership in various orders), \n",
    "\"BRIT\" (Britannicus).'''\n",
    "\n",
    "# Function to pull recognized inscriptions\n",
    "def coin_inscriptions(coin):\n",
    "    coin = f\" {str(coin)} \"\n",
    "    inscriptions_list = ['AVG', 'IMP', 'CAES', 'GERM', 'COS', 'CONSVL', 'PP', 'PO', 'PF',\n",
    "                         'SC', 'CENS', 'TPP', 'TR', 'RESTITVT', 'BRIT', 'AVGVSTVS', 'CAESAR',\n",
    "                         'C', 'TRIB POT', 'PON MAX', 'PM']\n",
    "    found_inscriptions = [i for i in inscriptions_list if f' {i} ' in coin]\n",
    "    unique_inscriptions = list(set(found_inscriptions))\n",
    "    return unique_inscriptions if unique_inscriptions else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function that combines previous helper functions to return coin DataFrame\n",
    "def coin_df(soup):\n",
    "    title = pull_title(soup)\n",
    "    subtitle = pull_subtitle(soup)\n",
    "    id, description, metal, mass, diameter, era, year, inscriptions, txt = [], [], [], [], [], [], [], [], []\n",
    "    for coin in pull_coins(soup):\n",
    "        id.append(coin_id(coin))\n",
    "        description.append(coin_description(coin))\n",
    "        metal.append(coin_metal(coin))\n",
    "        mass.append(coin_mass(coin))\n",
    "        diameter.append(coin_diameter(coin))\n",
    "        era.append(coin_era(coin))\n",
    "        year.append(coin_year(coin))\n",
    "        inscriptions.append(coin_inscriptions(coin))\n",
    "        txt.append(coin_txt(coin))\n",
    "    return pd.DataFrame({'ruler':title, 'ruler_detail':subtitle, 'id':id, 'description':description, 'metal':metal, 'mass':mass, \\\n",
    "                        'diameter':diameter, 'era':era, 'year':year, 'inscriptions':inscriptions, 'txt':txt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to combine multiple coin Dataframes\n",
    "def combine_coin_dfs(soups):\n",
    "    dfs = [coin_df(soup) for soup in soups]\n",
    "    filtered_dfs = [df for df in dfs if not df.empty and not df.isna().all().all()]\n",
    "    return pd.concat(filtered_dfs, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull html from all source pages\n",
    "''' (pulling from over 200 pages, which takes a couple hours with the 30 second \n",
    "delay between requests)'''\n",
    "\n",
    "# Scrape link directory\n",
    "with requests.get('https://www.wildwinds.com/coins/ric/i.html') as raw:\n",
    "    soup = BeautifulSoup(raw.content, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parse html data for a clean list of ruler names\n",
    "options = soup.find_all('option')\n",
    "emperors_raw = [i.contents for i in options if i.attrs['value'] != ''][:-6]\n",
    "emperors = []\n",
    "for line in emperors_raw:\n",
    "    for text in line:\n",
    "        emperors.append(text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate list of usable link roots for each Emperor's coin page\n",
    "# wildwinds.com/robots.txt requires a 30-second delay between requests\n",
    "linkroots = ['https://www.wildwinds.com/coins/ric/' + i.attrs['value'][:-6] for i in options if i.attrs['value'] != ''][:-6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping complete: 231/231                                                              \n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_pages = scrape(linkroots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parse html of each page using BeautifulSoup\n",
    "all_soups = [BeautifulSoup(page.content, 'lxml') for page in all_pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45807/24149481.py:5: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat(filtered_dfs, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine it all into a single Dataframe\n",
    "roman_coins_raw = combine_coin_dfs(all_soups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove duplicate coins\n",
    "roman_coins = roman_coins_raw.drop_duplicates(subset=['id'], keep='first').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map average year value of each ruler\n",
    "ruler_avg_year = {\n",
    "    ruler:round(roman_coins[roman_coins['ruler'] == ruler]['year'].mean(), 1) \n",
    "    for ruler in roman_coins['ruler'].unique().tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fill missing year values with average year value of matching ruler\n",
    "roman_coins.loc[roman_coins['year'].isna(), 'year'] = roman_coins['ruler'].map(ruler_avg_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop remaining NA year values\n",
    "roman_coins.dropna(subset='year', inplace=True)\n",
    "roman_coins['year'] = roman_coins['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map years to eras\n",
    "BC_coins = roman_coins['year'] < 0\n",
    "AD_coins = roman_coins['year'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fix era values to match year sign\n",
    "roman_coins.loc[BC_coins, 'era'] = 'BC'\n",
    "roman_coins.loc[AD_coins, 'era'] = 'AD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop entries with missing metal values\n",
    "roman_coins.dropna(subset=['metal'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove coins with outlier year values\n",
    "outlier_coins = (roman_coins['year'] < -50) | (roman_coins['year'] > 500)\n",
    "roman_coins = roman_coins[~outlier_coins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove entries still missing id value\n",
    "roman_coins.dropna(subset=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Consolidate missing value types\n",
    "roman_coins.replace([np.inf, -np.inf, np.nan], None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export roman_coins DataFrame as csv\n",
    "roman_coins.to_csv('roman_coins.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
